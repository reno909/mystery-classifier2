import streamlit as st
import pandas as pd
from janome.tokenizer import Tokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ãƒŸã‚¹ãƒ†ãƒªãƒ¼ãƒ»ãƒˆãƒªãƒƒã‚¯åˆ†é¡å™¨", layout="centered")

# --- 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å­¦ç¿’ ---
@st.cache_resource
def load_and_train():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv('mystery_dataset.csv', encoding='utf-8-sig')
    df.columns = df.columns.str.strip()
    
    t = Tokenizer()
    def tokenize(text):
        tokens = t.tokenize(str(text))
        return " ".join([token.base_form for token in tokens if token.part_of_speech.split(',')[0] in ['åè©', 'å‹•è©', 'å½¢å®¹è©']])
    
    df['tokenized_text'] = df['Trick_Summary'].apply(tokenize)
    
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df['tokenized_text'])
    y = df['Label']
    
    model = SVC(kernel='linear', probability=True)
    model.fit(X, y)
    return model, vectorizer, t, tokenize

model, vectorizer, t, tokenize = load_and_train()

# --- 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç®¡ç† ---
if "user_text" not in st.session_state:
    st.session_state.user_text = ""

def clear_text():
    st.session_state.user_text = ""

# --- 3. UI ---
st.title("ğŸ•µï¸â€â™‚ï¸ ãƒŸã‚¹ãƒ†ãƒªãƒ¼ãƒ»ãƒˆãƒªãƒƒã‚¯åˆ†é¡å™¨")
st.sidebar.info("å’æ¥­è«–æ–‡ç”¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—: æ±Ÿæˆ¸å·ä¹±æ­©ã€é¡åˆ¥ãƒˆãƒªãƒƒã‚¯é›†æˆã€ã«åŸºã¥ãåˆ†é¡")

st.subheader("ã‚ã‚‰ã™ã˜ï¼ˆã‚µãƒãƒªãƒ¼ï¼‰ã‚’å…¥åŠ›")

user_input = st.text_area(
    "ã‚ã‚‰ã™ã˜ã‚’è©³ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", 
    value=st.session_state.user_text,
    key="user_text_area",
    placeholder="ä¾‹ï¼šçŠ¯äººã¯è¢«å®³è€…ã®è¦ªå‹ã«ãªã‚Šã™ã¾ã—ã€å¤‰è£…ã—ã¦ç¾å ´ã‚’ç«‹ã¡å»ã£ãŸ...", 
    height=150
)
st.session_state.user_text = user_input

col1, col2 = st.columns([1, 1])
with col1:
    predict_btn = st.button("AIåˆ¤å®šã‚’é–‹å§‹", type="primary", use_container_width=True)
with col2:
    clear_btn = st.button("å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢", on_click=clear_text, use_container_width=True)

# --- 4. åˆ¤å®šã¨å¯è¦–åŒ– ---
if predict_btn:
    if st.session_state.user_text:
        tokenized_input = tokenize(st.session_state.user_text)
        vec_input = vectorizer.transform([tokenized_input])
        prob = model.predict_proba(vec_input)[0][1]
        
        st.divider()
        st.subheader("åˆ¤å®šçµæœ")
        
        if prob > 0.5:
            st.error(f"åˆ¤å®šï¼š **ä¸€äººäºŒå½¹ãƒˆãƒªãƒƒã‚¯ã®å¯èƒ½æ€§ãŒé«˜ã„**ï¼ˆç¢ºç‡: {prob*100:.1f}%ï¼‰")
        else:
            st.success(f"åˆ¤å®šï¼š **ä»–ã®ãƒˆãƒªãƒƒã‚¯ã®å¯èƒ½æ€§ãŒé«˜ã„**ï¼ˆç¢ºç‡: {prob*100:.1f}%ï¼‰")
        
        # --- ã“ã“ã‚’æ›¸ãæ›ãˆï¼šæ–‡å­—åŒ–ã‘ã—ãªã„Streamlitæ¨™æº–ã‚°ãƒ©ãƒ• ---
        st.write("#### ğŸ’¡ AIãŒæ³¨ç›®ã—ãŸå˜èª")
        
        feature_names = vectorizer.get_feature_names_out()
        coefs = model.coef_.toarray()[0]
        importance_df = pd.DataFrame({'å˜èª': feature_names, 'é‡è¦åº¦': coefs})
        
        # ä¸Šä½10å˜èªã‚’æŠ½å‡º
        top_words = importance_df.sort_values(by='é‡è¦åº¦', ascending=False).head(10)
        
        # Streamlitã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆMatplotlibã‚’ä½¿ã‚ãªã„ï¼‰
        st.bar_chart(data=top_words, x='å˜èª', y='é‡è¦åº¦', horizontal=True)
        
        st.caption("â€»ã‚°ãƒ©ãƒ•ã®æ•°å€¤ãŒé«˜ã„ã»ã©ã€AIãŒã€ä¸€äººäºŒå½¹ã€ã ã¨åˆ¤æ–­ã™ã‚‹å¼·ã„ææ–™ã«ãªã£ã¦ã„ã¾ã™ã€‚")
    else:
        st.warning("ã‚ã‚‰ã™ã˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")